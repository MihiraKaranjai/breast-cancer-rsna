{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pratyushraj07/inference-effnet?scriptVersionId=121184721\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-19T05:15:37.444975Z","iopub.execute_input":"2023-02-19T05:15:37.445487Z","iopub.status.idle":"2023-02-19T05:15:37.477427Z","shell.execute_reply.started":"2023-02-19T05:15:37.445383Z","shell.execute_reply":"2023-02-19T05:15:37.476552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    import pylibjpeg\nexcept:\n    !pip install -q /kaggle/input/rsna-2022-whl/{pydicom-2.3.0-py3-none-any.whl,pylibjpeg-1.4.0-py3-none-any.whl,python_gdcm-3.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl}\n    !pip install -q /kaggle/input/rsna-bcd-whl-ds/python_gdcm-3.0.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n    # !pip install -q /kaggle/input/rsna-bcd-whl-ds/pylibjpeg-1.4.0-py3-none-any.whl\n    !pip install -q /kaggle/input/rsna-bcd-whl-ds/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:15:37.481026Z","iopub.execute_input":"2023-02-19T05:15:37.481307Z","iopub.status.idle":"2023-02-19T05:17:19.696772Z","shell.execute_reply.started":"2023-02-19T05:15:37.481282Z","shell.execute_reply":"2023-02-19T05:17:19.695452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:19.698877Z","iopub.execute_input":"2023-02-19T05:17:19.69927Z","iopub.status.idle":"2023-02-19T05:17:21.597268Z","shell.execute_reply.started":"2023-02-19T05:17:19.699229Z","shell.execute_reply":"2023-02-19T05:17:21.596322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\"\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)\n        k  = nn.Sigmoid()\n        out = k(out)\n        out = torch.squeeze(out,1)\n        loss = F.binary_cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)\n        k  = nn.Sigmoid()\n        out = k(out)\n        out = torch.squeeze(out,1)\n        #print(out)\n        loss = F.binary_cross_entropy(out, labels)\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n         print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n        \ndef accuracy(outputs, labels):\n#     _, preds = torch.max(outputs, dim=1)\n#     print(outputs)\n#     print(labels)\n    for i in range(len(outputs)):\n        if (outputs[i]>0.5):\n            outputs[i] = 1\n        else:\n            outputs[i] = 0\n    return torch.tensor(torch.sum(outputs == labels).item() / len(outputs))\n\"\"\"    ","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:21.598815Z","iopub.execute_input":"2023-02-19T05:17:21.599444Z","iopub.status.idle":"2023-02-19T05:17:21.610464Z","shell.execute_reply.started":"2023-02-19T05:17:21.599406Z","shell.execute_reply":"2023-02-19T05:17:21.609494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:21.613958Z","iopub.execute_input":"2023-02-19T05:17:21.614983Z","iopub.status.idle":"2023-02-19T05:17:21.624975Z","shell.execute_reply.started":"2023-02-19T05:17:21.614948Z","shell.execute_reply":"2023-02-19T05:17:21.623955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndevice = get_default_device()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:21.626228Z","iopub.execute_input":"2023-02-19T05:17:21.626918Z","iopub.status.idle":"2023-02-19T05:17:21.717688Z","shell.execute_reply.started":"2023-02-19T05:17:21.626881Z","shell.execute_reply":"2023-02-19T05:17:21.716599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nfrom timm import create_model\nfrom tqdm.notebook import tqdm\nfrom joblib import Parallel, delayed\nimport cv2\nimport dicomsdl","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:21.719328Z","iopub.execute_input":"2023-02-19T05:17:21.720114Z","iopub.status.idle":"2023-02-19T05:17:22.863433Z","shell.execute_reply.started":"2023-02-19T05:17:21.720077Z","shell.execute_reply":"2023-02-19T05:17:22.862372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODELS_PATH = '/kaggle/input/wandb-models/models'\nDCM_TEST_IMAGES_PATH = f'/kaggle/input/rsna-breast-cancer-detection/test_images'","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:22.864996Z","iopub.execute_input":"2023-02-19T05:17:22.865378Z","iopub.status.idle":"2023-02-19T05:17:22.872554Z","shell.execute_reply.started":"2023-02-19T05:17:22.86533Z","shell.execute_reply":"2023-02-19T05:17:22.871449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm\n\nclass EfficientNet_b0(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = timm.create_model(\"efficientnet_b0\")\n        # Replace last layer\n        num_ftrs = self.network.classifier.in_features\n#         self.network.classifier = nn.Linear(num_ftrs,3)7\n        self.network.classifier = torch.nn.Sequential(torch.nn.Linear(num_ftrs,1))\n    \n    def forward(self, xb):\n        return self.network(xb)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:22.874264Z","iopub.execute_input":"2023-02-19T05:17:22.874643Z","iopub.status.idle":"2023-02-19T05:17:22.885361Z","shell.execute_reply.started":"2023-02-19T05:17:22.874608Z","shell.execute_reply":"2023-02-19T05:17:22.884398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:22.887046Z","iopub.execute_input":"2023-02-19T05:17:22.887405Z","iopub.status.idle":"2023-02-19T05:17:22.89574Z","shell.execute_reply.started":"2023-02-19T05:17:22.887372Z","shell.execute_reply":"2023-02-19T05:17:22.894699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"effnet_b0 = EfficientNet_b0()\neffnet_b0 = effnet_b0.to(device)\nmodel = effnet_b0","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:22.897048Z","iopub.execute_input":"2023-02-19T05:17:22.897902Z","iopub.status.idle":"2023-02-19T05:17:26.027098Z","shell.execute_reply.started":"2023-02-19T05:17:22.897868Z","shell.execute_reply":"2023-02-19T05:17:26.026101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from torchvision import models \n# model = models.efficientnet_b0()\n\n# #model.load_state_dict(\"/kaggle/input/timm-pretrained-efficientnet/efficientnet/efficientnet_b0_ra-3dd342df.pth\")\n# model.classifier = nn.Sequential(\n#     nn.Linear(in_features=model.classifier.in_features, out_features=1)\n# )\n# #model","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:26.028592Z","iopub.execute_input":"2023-02-19T05:17:26.029191Z","iopub.status.idle":"2023-02-19T05:17:26.033742Z","shell.execute_reply.started":"2023-02-19T05:17:26.029155Z","shell.execute_reply":"2023-02-19T05:17:26.032721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/input/effenetb0final/checknew.pth\", map_location=device))\n#model = torch.load(\"check.pth\")\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:26.03527Z","iopub.execute_input":"2023-02-19T05:17:26.035629Z","iopub.status.idle":"2023-02-19T05:17:26.4597Z","shell.execute_reply.started":"2023-02-19T05:17:26.035595Z","shell.execute_reply":"2023-02-19T05:17:26.458803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#eff = '/kaggle/input/timm-pretrained-efficientnet/efficientnet/efficientnet_b0_ra-3dd342df.pth'","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:26.464541Z","iopub.execute_input":"2023-02-19T05:17:26.464825Z","iopub.status.idle":"2023-02-19T05:17:26.470214Z","shell.execute_reply.started":"2023-02-19T05:17:26.464799Z","shell.execute_reply":"2023-02-19T05:17:26.469239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class MyEffNetB0Model(nn.Module):\n#     def __init__(self):\n#         super(MyEffNetB0Model, self).__init__()\n        \n#         # Load a pre-defined EfficientNet-B0 model\n#         self.network = timm.create_model(eff, pretrained=False)\n        \n#         # Replace the last layer with your own output layer\n#         num_ftrs = self.network.classifier.in_features\n#         self.network.classifier = nn.Linear(num_ftrs, num_classes)\n\n#     def forward(self, x):\n#         # Define the forward pass of your model here\n#         return self.network(x)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:26.471744Z","iopub.execute_input":"2023-02-19T05:17:26.472299Z","iopub.status.idle":"2023-02-19T05:17:26.47989Z","shell.execute_reply.started":"2023-02-19T05:17:26.472265Z","shell.execute_reply":"2023-02-19T05:17:26.478877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nsys.path.append(\"../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master\")","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:26.481376Z","iopub.execute_input":"2023-02-19T05:17:26.482002Z","iopub.status.idle":"2023-02-19T05:17:26.492188Z","shell.execute_reply.started":"2023-02-19T05:17:26.48197Z","shell.execute_reply":"2023-02-19T05:17:26.491063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from efficientnet_pytorch import model as enet\n# from efficientnet_pytorch import EfficientNet\n\n# # # Initialize the model\n# model = EfficientNet.from_name('efficientnet-b0')","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:26.49367Z","iopub.execute_input":"2023-02-19T05:17:26.494243Z","iopub.status.idle":"2023-02-19T05:17:26.502557Z","shell.execute_reply.started":"2023-02-19T05:17:26.494208Z","shell.execute_reply":"2023-02-19T05:17:26.501568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model._fc = nn.Sequential(\n#     nn.Linear(in_features=model._fc.in_features, out_features=1)\n# )","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:26.504003Z","iopub.execute_input":"2023-02-19T05:17:26.504628Z","iopub.status.idle":"2023-02-19T05:17:26.513679Z","shell.execute_reply.started":"2023-02-19T05:17:26.504593Z","shell.execute_reply":"2023-02-19T05:17:26.512727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import joblib\n\n# # Load the model from the file in the input directory\n# model_path = \"/kaggle/input/efficientnet-pytorch/efficientnet-b0-08094119.pth\"\n# model = joblib.load(model_path)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:26.515019Z","iopub.execute_input":"2023-02-19T05:17:26.51569Z","iopub.status.idle":"2023-02-19T05:17:26.523376Z","shell.execute_reply.started":"2023-02-19T05:17:26.515656Z","shell.execute_reply":"2023-02-19T05:17:26.522297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model,val_dl):\n    torch.manual_seed(42)\n    pred_cancer = []\n    with torch.no_grad():\n        model.eval()\n        losses = []\n        targets = []\n        with tqdm(val_dl,desc='Eval',mininterval=30) as eval_progress:\n            for i,batch in enumerate(eval_progress):\n                with autocast(enabled=True):\n                    imgs,labels = batch\n                    cancer_pred = model.forward(imgs)\n                    loss = F.binary_cross_entropy_with_logits(\n                            cancer_pred,\n                            labels.to(float),\n                            pos_weight = torch.tensor([20]).to(device)\n                        ).item()\n                    losses.append(loss)\n                    pred_cancer.append(torch.sigmoid(cancer_pred))\n                    targets.append(labels.cpu().numpy())\n        targets = np.concatenate(targets)\n        pred = torch.concat(pred_cancer).cpu().numpy()\n    return np.mean(losses)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:26.524867Z","iopub.execute_input":"2023-02-19T05:17:26.52546Z","iopub.status.idle":"2023-02-19T05:17:26.535894Z","shell.execute_reply.started":"2023-02-19T05:17:26.525427Z","shell.execute_reply":"2023-02-19T05:17:26.534848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install timm -q","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:26.537229Z","iopub.execute_input":"2023-02-19T05:17:26.537743Z","iopub.status.idle":"2023-02-19T05:17:56.105933Z","shell.execute_reply.started":"2023-02-19T05:17:26.537711Z","shell.execute_reply":"2023-02-19T05:17:56.104737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:56.110093Z","iopub.execute_input":"2023-02-19T05:17:56.11339Z","iopub.status.idle":"2023-02-19T05:17:56.119401Z","shell.execute_reply.started":"2023-02-19T05:17:56.113349Z","shell.execute_reply":"2023-02-19T05:17:56.117954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.load_state_dict(torch.load(\"/kaggle/input/effenetb0final/checknew.pth\", map_location=device))\n#model = torch.load(\"check.pth\")\n#model.eval()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:56.122188Z","iopub.execute_input":"2023-02-19T05:17:56.123122Z","iopub.status.idle":"2023-02-19T05:17:56.131622Z","shell.execute_reply.started":"2023-02-19T05:17:56.123088Z","shell.execute_reply":"2023-02-19T05:17:56.130547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\ntrain_df = pd.read_csv('/kaggle/input/rsna-datadrame/rsna_df.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:56.133421Z","iopub.execute_input":"2023-02-19T05:17:56.134149Z","iopub.status.idle":"2023-02-19T05:17:56.400208Z","shell.execute_reply.started":"2023-02-19T05:17:56.134115Z","shell.execute_reply":"2023-02-19T05:17:56.399231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PNG_TEST_IMAGES_PATH = f'/kaggle/working/test'\nDCM_TEST_IMAGES_PATH = f'/kaggle/input/rsna-breast-cancer-detection/test_images'","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:56.404973Z","iopub.execute_input":"2023-02-19T05:17:56.407161Z","iopub.status.idle":"2023-02-19T05:17:56.414623Z","shell.execute_reply.started":"2023-02-19T05:17:56.407123Z","shell.execute_reply":"2023-02-19T05:17:56.412131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\nimport re\nimport pydicom\nfrom tqdm import tqdm\nimport glob\nimport cv2\nimport os\n\ndef fit_image(fname, size=1024):\n    # 1. Read, resize\n    \n    \n    patient = fname.split('/')[-2]\n    image = fname.split('/')[-1][:-4]\n    dicom = pydicom.dcmread(fname)\n    img = dicom.pixel_array\n    img = (img - img.min()) / (img.max() - img.min())\n    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        img = 1 - img\n    img = cv2.resize(img, (size, size))\n    \n    # 2. Crop\n    X = img\n    # Some images have narrow exterior \"frames\" that complicate selection of the main data. Cutting off the frame\n    X = X[5:-5, 5:-5]\n    \n    \n    # regions of non-empty pixels\n    output= cv2.connectedComponentsWithStats((X > 0.05).astype(np.uint8)[:, :], 8, cv2.CV_32S)\n    stats = output[2]\n    \n    # finding max area which always corresponds to the breast data. \n    idx = stats[1:, 4].argmax() + 1\n    x1, y1, w, h = stats[idx][:4]\n    x2 = x1 + w\n    y2 = y1 + h\n    \n    # cutting out the breast data\n    X_fit = X[y1: y2, x1: x2]    \n    patient_id, im_id = os.path.basename(os.path.dirname(fname)), os.path.basename(fname)[:-4]\n    os.makedirs(f'{PNG_TEST_IMAGES_PATH}/{patient_id}', exist_ok=True)\n    cv2.imwrite(f'{PNG_TEST_IMAGES_PATH}/{patient_id}/{im_id}.png', (X_fit[:, :] * 255).astype(np.uint8))\n\ndef fit_all_images(all_images):\n    with ThreadPoolExecutor(2) as p:\n        for i in tqdm(p.map(fit_image, all_images), total=len(all_images)):\n            pass\n\nall_images = glob.glob('/kaggle/input/rsna-breast-cancer-detection/test_images/*/*') \n# all_images = glob.glob('/kaggle/input/rsna-breast-cancer-detection/train_images/10006/*')\nfit_all_images(all_images)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:56.419431Z","iopub.execute_input":"2023-02-19T05:17:56.422131Z","iopub.status.idle":"2023-02-19T05:17:58.948008Z","shell.execute_reply.started":"2023-02-19T05:17:56.422094Z","shell.execute_reply":"2023-02-19T05:17:58.946964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img_path ='/kaggle/working/test/'","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:58.949696Z","iopub.execute_input":"2023-02-19T05:17:58.950051Z","iopub.status.idle":"2023-02-19T05:17:58.954784Z","shell.execute_reply.started":"2023-02-19T05:17:58.950013Z","shell.execute_reply":"2023-02-19T05:17:58.953714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:58.956196Z","iopub.execute_input":"2023-02-19T05:17:58.957327Z","iopub.status.idle":"2023-02-19T05:17:58.979177Z","shell.execute_reply.started":"2023-02-19T05:17:58.957286Z","shell.execute_reply":"2023-02-19T05:17:58.978158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = train_df.copy()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:58.980576Z","iopub.execute_input":"2023-02-19T05:17:58.981391Z","iopub.status.idle":"2023-02-19T05:17:58.989161Z","shell.execute_reply.started":"2023-02-19T05:17:58.981356Z","shell.execute_reply":"2023-02-19T05:17:58.988053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:58.99061Z","iopub.execute_input":"2023-02-19T05:17:58.991337Z","iopub.status.idle":"2023-02-19T05:17:59.000847Z","shell.execute_reply.started":"2023-02-19T05:17:58.991302Z","shell.execute_reply":"2023-02-19T05:17:58.999973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_path = test_img_path\nall_paths = []\nfor k in tqdm(range(len(test_df))):\n    row = test_df.iloc[k, :]\n    all_paths.append(base_path  +str(row.patient_id)+\"/\"+str(row.image_id) +\".png\")\n    \ntest_df[\"path\"] = all_paths","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:59.002201Z","iopub.execute_input":"2023-02-19T05:17:59.00304Z","iopub.status.idle":"2023-02-19T05:17:59.019236Z","shell.execute_reply.started":"2023-02-19T05:17:59.002998Z","shell.execute_reply":"2023-02-19T05:17:59.018057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:59.020766Z","iopub.execute_input":"2023-02-19T05:17:59.021329Z","iopub.status.idle":"2023-02-19T05:17:59.034755Z","shell.execute_reply.started":"2023-02-19T05:17:59.021296Z","shell.execute_reply":"2023-02-19T05:17:59.033808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:59.035893Z","iopub.execute_input":"2023-02-19T05:17:59.036197Z","iopub.status.idle":"2023-02-19T05:17:59.053535Z","shell.execute_reply.started":"2023-02-19T05:17:59.036156Z","shell.execute_reply":"2023-02-19T05:17:59.052532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:59.054911Z","iopub.execute_input":"2023-02-19T05:17:59.055328Z","iopub.status.idle":"2023-02-19T05:17:59.068051Z","shell.execute_reply.started":"2023-02-19T05:17:59.055294Z","shell.execute_reply":"2023-02-19T05:17:59.066988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_test = test_df[\"path\"] ","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:59.069607Z","iopub.execute_input":"2023-02-19T05:17:59.070389Z","iopub.status.idle":"2023-02-19T05:17:59.076789Z","shell.execute_reply.started":"2023-02-19T05:17:59.070354Z","shell.execute_reply":"2023-02-19T05:17:59.075774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:59.078201Z","iopub.execute_input":"2023-02-19T05:17:59.078874Z","iopub.status.idle":"2023-02-19T05:17:59.086613Z","shell.execute_reply.started":"2023-02-19T05:17:59.078841Z","shell.execute_reply":"2023-02-19T05:17:59.085983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Target = 'cancer'\nclass RSNADataset(Dataset):\n    def __init__(self, df, transforms=None):\n        super().__init__()\n        self.df = df\n        self.img_path = list(df['path'])\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img = self.img_path[idx]\n        img = Image.open(img).convert('RGB')\n        if (self.transforms!=None):\n            img = self.transforms(img)\n        \n        if Target in self.df.columns:\n            target = self.df.loc[idx,'cancer']\n            return img,torch.tensor(np.array([target]))\n        return img","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:59.088059Z","iopub.execute_input":"2023-02-19T05:17:59.088836Z","iopub.status.idle":"2023-02-19T05:17:59.097837Z","shell.execute_reply.started":"2023-02-19T05:17:59.088801Z","shell.execute_reply":"2023-02-19T05:17:59.09711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\nfrom PIL import Image\n\ndef get_transforms(aug=False):\n\n    def transforms(img):\n#         img = img.convert('RGB')#.resize((512, 512))\n        if aug:\n            tfm = [\n                torchvision.transforms.RandomHorizontalFlip(0.5),\n                torchvision.transforms.RandomRotation(degrees=(-5, 5)), \n                torchvision.transforms.RandomResizedCrop((1024, 512), scale=(0.8, 1), ratio=(0.45, 0.55)) \n            ]\n        else:\n            tfm = [\n                torchvision.transforms.RandomHorizontalFlip(0.5),\n                torchvision.transforms.RandomVerticalFlip(0.5),\n                torchvision.transforms.Resize((256,256))\n            ]\n        img = torchvision.transforms.Compose(tfm + [            \n            torchvision.transforms.ToTensor(),\n            torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            \n        ])(img)\n        return img\n    return lambda img: transforms(img)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:59.099192Z","iopub.execute_input":"2023-02-19T05:17:59.099949Z","iopub.status.idle":"2023-02-19T05:17:59.108759Z","shell.execute_reply.started":"2023-02-19T05:17:59.099915Z","shell.execute_reply":"2023-02-19T05:17:59.107886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:59.110186Z","iopub.execute_input":"2023-02-19T05:17:59.110921Z","iopub.status.idle":"2023-02-19T05:17:59.12642Z","shell.execute_reply.started":"2023-02-19T05:17:59.110887Z","shell.execute_reply":"2023-02-19T05:17:59.125636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds =RSNADataset(test_df,get_transforms(False))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:59.127896Z","iopub.execute_input":"2023-02-19T05:17:59.128703Z","iopub.status.idle":"2023-02-19T05:17:59.135312Z","shell.execute_reply.started":"2023-02-19T05:17:59.128668Z","shell.execute_reply":"2023-02-19T05:17:59.134411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader = DataLoader(test_ds, batch_size=16,shuffle=False,num_workers=2,pin_memory=True)\ntest_dl_final = DeviceDataLoader(test_loader,device)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:59.143085Z","iopub.execute_input":"2023-02-19T05:17:59.143346Z","iopub.status.idle":"2023-02-19T05:17:59.149027Z","shell.execute_reply.started":"2023-02-19T05:17:59.143323Z","shell.execute_reply":"2023-02-19T05:17:59.147857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_pred = []\nfor image in test_dl_final:\n    \n    pred = model(image).cpu().detach().numpy()\n    # print(pred.cpu().detach().numpy())\n    for i in range(len(pred)):\n        cnn_pred.append(pred[i])","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:17:59.150557Z","iopub.execute_input":"2023-02-19T05:17:59.150907Z","iopub.status.idle":"2023-02-19T05:18:05.46831Z","shell.execute_reply.started":"2023-02-19T05:17:59.150873Z","shell.execute_reply":"2023-02-19T05:18:05.466912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_pred","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:18:05.470655Z","iopub.execute_input":"2023-02-19T05:18:05.471112Z","iopub.status.idle":"2023-02-19T05:18:05.4816Z","shell.execute_reply.started":"2023-02-19T05:18:05.471062Z","shell.execute_reply":"2023-02-19T05:18:05.480246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ans = []\nfor i in range(len(cnn_pred)):\n    x = torch.from_numpy(cnn_pred[i])\n    m = nn.Sigmoid()\n    z = m(x)\n    ans.append(z)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:18:05.483675Z","iopub.execute_input":"2023-02-19T05:18:05.48461Z","iopub.status.idle":"2023-02-19T05:18:05.492818Z","shell.execute_reply.started":"2023-02-19T05:18:05.484517Z","shell.execute_reply":"2023-02-19T05:18:05.491469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:18:05.494923Z","iopub.execute_input":"2023-02-19T05:18:05.495787Z","iopub.status.idle":"2023-02-19T05:18:05.515974Z","shell.execute_reply.started":"2023-02-19T05:18:05.495743Z","shell.execute_reply":"2023-02-19T05:18:05.514849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = test_df\ndf_test['cancer'] = ans\ndf_sub = df_test.groupby('prediction_id')[['cancer']].mean().reset_index()\ndf_sub","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:18:05.517804Z","iopub.execute_input":"2023-02-19T05:18:05.518766Z","iopub.status.idle":"2023-02-19T05:18:05.546572Z","shell.execute_reply.started":"2023-02-19T05:18:05.518723Z","shell.execute_reply":"2023-02-19T05:18:05.545179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"THRES = .6\ndf_sub['cancer'] = (df_sub.cancer > THRES).astype(float)\ndf_sub","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:18:05.548536Z","iopub.execute_input":"2023-02-19T05:18:05.549434Z","iopub.status.idle":"2023-02-19T05:18:05.561804Z","shell.execute_reply.started":"2023-02-19T05:18:05.549392Z","shell.execute_reply":"2023-02-19T05:18:05.560609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T05:18:05.563756Z","iopub.execute_input":"2023-02-19T05:18:05.564536Z","iopub.status.idle":"2023-02-19T05:18:05.572911Z","shell.execute_reply.started":"2023-02-19T05:18:05.564477Z","shell.execute_reply":"2023-02-19T05:18:05.571775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}